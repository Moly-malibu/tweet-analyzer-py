{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Community Analysis\n",
    "Use this notebook to analyze communities in bot retweet network\n",
    "\n",
    "Data = Bot profiles and community membership, bot tweets\n",
    "\n",
    "Analysis steps\n",
    "\n",
    "1) Look at popular retweeted users, arabic profiles, and account creation dates within in bot retweet community.\n",
    "\n",
    "3) Cluster bots by creation date.  Look at popular retweeted users and arabic profiles in each created_at community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "import sqlite3,sys,os,string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from helper_retweet_network import *\n",
    "\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "#import arabic_reshaper\n",
    "#from bidi.algorithm import get_display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Input:\n",
    "\n",
    "1) fname_bots_db = file of database with bot tweets\n",
    "\n",
    "2) fname_Gretweet = file where we saved the bot retweet network\n",
    "\n",
    "3) fname_Gsim = file where we saved retweet similarity network of bots\n",
    "\n",
    "Output: \n",
    "\n",
    "1) df_profiles = dataframe with both profiles and created_at as a datetime object\n",
    "\n",
    "2) df_communities = dataframe with bot profiles and communities\n",
    "\n",
    "3) Gretweet = retweet network including bots and who they retweet\n",
    "\n",
    "4) Gsim = similarity graph of bot accounts based on Jacard index of similarity network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026 bots\n",
      "413974 bot tweets\n",
      "3 bot communities\n"
     ]
    }
   ],
   "source": [
    "path_data = \"Libya//\"\n",
    "\n",
    "fname_bots_db = path_data+\"Libya_bot_forensics.db\"\n",
    "fname_Gretweet = path_data + \"Gretweet.gpickle\"\n",
    "fname_Gsim = path_data + \"Gsim.gpickle\"\n",
    "fname_bots_updated_csv = path_data+\"Libya_bot_forensics_community.csv\"\n",
    "conn = sqlite3.connect(\"%s\"%fname_bots_db)\n",
    "df_tweets = pd.read_sql_query(\"SELECT * FROM tweet\", conn)\n",
    "df_profiles = pd.read_sql_query(\"SELECT * FROM user_profile\", conn)\n",
    "df_communities = pd.read_csv(fname_bots_updated_csv)\n",
    "Gretweet = nx.read_gpickle(fname_Gretweet)\n",
    "Gsim = nx.read_gpickle(fname_Gsim)\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "#convert created_at to a datetime object\n",
    "Tdatetime = []\n",
    "for s in df_profiles.created_at:\n",
    "    date_time_obj = datetime.strptime(s, fmt)\n",
    "    Tdatetime.append(date_time_obj)\n",
    "Tdatetime = np.array(Tdatetime)\n",
    "df_profiles[\"created_at_datetime\"]  = Tdatetime\n",
    "Tdatetime = []\n",
    "for s in df_communities.created_at:\n",
    "    date_time_obj = datetime.strptime(s, fmt)\n",
    "    Tdatetime.append(date_time_obj)\n",
    "Tdatetime = np.array(Tdatetime)\n",
    "df_communities[\"created_at_datetime\"]  = Tdatetime\n",
    "\n",
    "\n",
    "t0 = min(Tdatetime)\n",
    "ncomm  = max(df_communities.Community)+1\n",
    "\n",
    "print(\"%s bots\\n%s bot tweets\\n%s bot communities\"%(len(df_profiles),\n",
    "                                                    len(df_tweets),\n",
    "                                                    ncomm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect Arabic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to detect if a string has arabic characters\n",
    "def isarabic_char(ch):\n",
    "    if ('\\u0600' <= ch <= '\\u06FF' or\n",
    "        '\\u0750' <= ch <= '\\u077F' or\n",
    "        '\\u08A0' <= ch <= '\\u08FF' or\n",
    "        '\\uFB50' <= ch <= '\\uFDFF' or\n",
    "        '\\uFE70' <= ch <= '\\uFEFF' or\n",
    "        '\\U00010E60' <= ch <= '\\U00010E7F' or\n",
    "        '\\U0001EE00' <= ch <= '\\U0001EEFF' or\n",
    "                        ch == '\\U0001F1E6' or #saudi flag emoji\n",
    "                        ch == '\\U0001F1E6'): #saudi flag emoji\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def isarabic_str(str):\n",
    "    x = False\n",
    "    for ch in str:\n",
    "        if isarabic_char(ch): \n",
    "            x = True\n",
    "            break\n",
    "    return(x)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraction of Arabic profiles in each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 0 has 0.41 percent Arab profiles\n",
      "Community 1 has 0.41 percent Arab profiles\n",
      "Community 2 has 0.03 percent Arab profiles\n"
     ]
    }
   ],
   "source": [
    "for counter in range(ncomm):\n",
    "    mask_arab = df_communities.arabic_profile==True\n",
    "    mask_comm = df_communities.Community==counter\n",
    "    nc = len(list(df_communities.screen_name[mask_comm]))\n",
    "    nc_arab = len(list(df_communities.screen_name[mask_comm & mask_arab]))\n",
    "    frac_arab = nc_arab/nc\n",
    "    print(\"Community %s has %.2f percent Arab profiles\"%(counter,frac_arab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top retweeted users in each community\n",
    "\n",
    "For each community of bots, we form the subgraph containing the bots and everyone they retweet.  Then we look at the top retweeted users in this subgraph.\n",
    "\n",
    "Input\n",
    "\n",
    "1) display_max = number of retweet sources to display for each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweet community 0 with 1073 users\n",
      "Top out degree\n",
      "\tCentrality = 512.00,  monther72\n",
      "\tCentrality = 457.00,  TurkeyAffairs\n",
      "\tCentrality = 424.00,  5a1di\n",
      "\tCentrality = 392.00,  AlArabiya\n",
      "\tCentrality = 377.00,  meshaluk\n",
      "\tCentrality = 357.00,  70sul\n",
      "\tCentrality = 318.00,  AlArabiya_Brk\n",
      "\tCentrality = 300.00,  sattam_al_saud\n",
      "\tCentrality = 289.00,  amjadt25\n",
      "\tCentrality = 289.00,  naif4002\n",
      "\tCentrality = 287.00,  Alshaikh2\n",
      "\tCentrality = 266.00,  KSA24\n",
      "\tCentrality = 263.00,  amhfarraj\n",
      "\tCentrality = 240.00,  SalmanAldosary\n",
      "\tCentrality = 238.00,  fdeet_alnssr\n",
      "\tCentrality = 231.00,  SAUDI_POWER0\n",
      "\tCentrality = 226.00,  Dr_SultanAsqah\n",
      "\tCentrality = 222.00,  SPAregions\n",
      "\tCentrality = 211.00,  alekhbariyatv\n",
      "\tCentrality = 208.00,  AlHadath\n",
      "\tCentrality = 199.00,  s_hm2030\n",
      "Retweet community 1 with 757 users\n",
      "Top out degree\n",
      "\tCentrality = 421.00,  EbrahimGasuda\n",
      "\tCentrality = 374.00,  emad_badish\n",
      "\tCentrality = 320.00,  RD_turk\n",
      "\tCentrality = 304.00,  nasser_duwailah\n",
      "\tCentrality = 296.00,  TurkiShalhoub\n",
      "\tCentrality = 295.00,  QATARTEAM\n",
      "\tCentrality = 294.00,  full_confident\n",
      "\tCentrality = 275.00,  Hamza_tekin2023\n",
      "\tCentrality = 270.00,  mshinqiti\n",
      "\tCentrality = 229.00,  aa_arabic\n",
      "\tCentrality = 228.00,  akarh90\n",
      "\tCentrality = 216.00,  TRTArabi\n",
      "\tCentrality = 212.00,  AJArabic\n",
      "\tCentrality = 205.00,  hureyaksa\n",
      "\tCentrality = 186.00,  jaberalharmi\n",
      "\tCentrality = 186.00,  ghadaoueiss\n",
      "\tCentrality = 176.00,  nbenotman\n",
      "\tCentrality = 174.00,  RQ_QATAR\n",
      "\tCentrality = 166.00,  ismail_yasa\n",
      "\tCentrality = 165.00,  TamerMisshal\n",
      "\tCentrality = 165.00,  ajmubasher\n",
      "Retweet community 2 with 195 users\n",
      "Top out degree\n",
      "\tCentrality = 152.00,  tcsavunma\n",
      "\tCentrality = 113.00,  FazilDuygun\n",
      "\tCentrality = 109.00,  drfahrettinkoca\n",
      "\tCentrality = 109.00,  Selcuk\n",
      "\tCentrality = 101.00,  birincimucahit\n",
      "\tCentrality = 100.00,  yazarmuratakan\n",
      "\tCentrality = 95.00,  nedimsener2010\n",
      "\tCentrality = 94.00,  yerelkulis\n",
      "\tCentrality = 93.00,  06melihgokcek\n",
      "\tCentrality = 92.00,  suleymansoylu\n",
      "\tCentrality = 89.00,  yusufalabarda\n",
      "\tCentrality = 89.00,  haciykk\n",
      "\tCentrality = 88.00,  ibrahimkaragul\n",
      "\tCentrality = 86.00,  FUATUGUR\n",
      "\tCentrality = 84.00,  EtmedikPes_\n",
      "\tCentrality = 84.00,  RTErdogan\n",
      "\tCentrality = 82.00,  asoszen\n",
      "\tCentrality = 79.00,  THEMARGlNALE\n",
      "\tCentrality = 78.00,  enveryan\n",
      "\tCentrality = 75.00,  medyaadami\n",
      "\tCentrality = 75.00,  abdullahciftcib\n"
     ]
    }
   ],
   "source": [
    "display_max = 20  #number of nodes to display\n",
    "\n",
    "for counter in range(ncomm):\n",
    "    community_screen_names = list(df_communities.screen_name[df_communities.Community==counter])\n",
    "    Vsub = []\n",
    "    for v in community_screen_names:\n",
    "        if Gretweet.has_node(v):\n",
    "            nb = list(Gretweet.predecessors(v))\n",
    "            Vsub+=nb\n",
    "            Vsub.append(v)\n",
    "    \n",
    "    print(\"Retweet community %s with %s users\"%(counter,len(community_screen_names)))\n",
    "    G = Gretweet.subgraph(Vsub)\n",
    "    Dout = dict(G.out_degree())\n",
    "    print(\"Top out degree\")\n",
    "    Centrality = Dout\n",
    "    display_top_centrality_nodes(Centrality,display_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top retweeted users in each (retweet,profile language) community \n",
    "\n",
    "For each retweet community of bots, we separate out those\n",
    "with Arabic and non-Arabic profies.  \n",
    "We form the subgraph containing the bots and everyone they retweet.  \n",
    "Then we look at the top retweeted users in this subgraph.\n",
    "\n",
    "Input\n",
    "\n",
    "1) display_max = number of retweet sources to display for each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic profile retweet community 0 with 435 users\n",
      "Top out degree\n",
      "\tCentrality = 309.00,  monther72\n",
      "\tCentrality = 283.00,  TurkeyAffairs\n",
      "\tCentrality = 261.00,  5a1di\n",
      "\tCentrality = 241.00,  AlArabiya\n",
      "\tCentrality = 227.00,  meshaluk\n",
      "\tCentrality = 215.00,  70sul\n",
      "\tCentrality = 192.00,  sattam_al_saud\n",
      "\tCentrality = 190.00,  AlArabiya_Brk\n",
      "\tCentrality = 174.00,  naif4002\n",
      "\tCentrality = 171.00,  Alshaikh2\n",
      "\tCentrality = 169.00,  amjadt25\n",
      "Arabic profile retweet community 1 with 309 users\n",
      "Top out degree\n",
      "\tCentrality = 218.00,  EbrahimGasuda\n",
      "\tCentrality = 192.00,  emad_badish\n",
      "\tCentrality = 168.00,  RD_turk\n",
      "\tCentrality = 162.00,  full_confident\n",
      "\tCentrality = 158.00,  QATARTEAM\n",
      "\tCentrality = 152.00,  nasser_duwailah\n",
      "\tCentrality = 144.00,  TurkiShalhoub\n",
      "\tCentrality = 134.00,  Hamza_tekin2023\n",
      "\tCentrality = 132.00,  akarh90\n",
      "\tCentrality = 129.00,  mshinqiti\n",
      "\tCentrality = 119.00,  aa_arabic\n",
      "Arabic profile retweet community 2 with 6 users\n",
      "Top out degree\n",
      "\tCentrality = 4.00,  AliBakeer\n",
      "\tCentrality = 4.00,  RD_turk\n",
      "\tCentrality = 3.00,  TurkiShalhoub\n",
      "\tCentrality = 3.00,  emad_badish\n",
      "\tCentrality = 3.00,  fdwairi\n",
      "\tCentrality = 3.00,  k7ybnd99\n",
      "\tCentrality = 3.00,  janreno__\n",
      "\tCentrality = 3.00,  mshinqiti\n",
      "\tCentrality = 3.00,  istanbulli1453\n",
      "\tCentrality = 3.00,  full_confident\n",
      "\tCentrality = 3.00,  tcsavunma\n",
      "\n",
      "Non-Arabic profile retweet community 0 with 638 users\n",
      "Top out degree\n",
      "\tCentrality = 233.00,  monther72\n",
      "\tCentrality = 206.00,  TurkeyAffairs\n",
      "\tCentrality = 188.00,  5a1di\n",
      "\tCentrality = 177.00,  AlArabiya\n",
      "\tCentrality = 168.00,  meshaluk\n",
      "\tCentrality = 161.00,  70sul\n",
      "\tCentrality = 151.00,  AlArabiya_Brk\n",
      "\tCentrality = 138.00,  amjadt25\n",
      "\tCentrality = 131.00,  naif4002\n",
      "\tCentrality = 130.00,  tcsavunma\n",
      "\tCentrality = 126.00,  Alshaikh2\n",
      "\n",
      "Non-Arabic profile retweet community 1 with 448 users\n",
      "Top out degree\n",
      "\tCentrality = 232.00,  EbrahimGasuda\n",
      "\tCentrality = 210.00,  emad_badish\n",
      "\tCentrality = 176.00,  RD_turk\n",
      "\tCentrality = 171.00,  TurkiShalhoub\n",
      "\tCentrality = 169.00,  nasser_duwailah\n",
      "\tCentrality = 158.00,  mshinqiti\n",
      "\tCentrality = 157.00,  Hamza_tekin2023\n",
      "\tCentrality = 155.00,  QATARTEAM\n",
      "\tCentrality = 153.00,  full_confident\n",
      "\tCentrality = 138.00,  tcsavunma\n",
      "\tCentrality = 128.00,  aa_arabic\n",
      "\n",
      "Non-Arabic profile retweet community 2 with 189 users\n",
      "Top out degree\n",
      "\tCentrality = 151.00,  tcsavunma\n",
      "\tCentrality = 112.00,  FazilDuygun\n",
      "\tCentrality = 108.00,  drfahrettinkoca\n",
      "\tCentrality = 108.00,  Selcuk\n",
      "\tCentrality = 101.00,  birincimucahit\n",
      "\tCentrality = 99.00,  yazarmuratakan\n",
      "\tCentrality = 94.00,  nedimsener2010\n",
      "\tCentrality = 93.00,  yerelkulis\n",
      "\tCentrality = 92.00,  06melihgokcek\n",
      "\tCentrality = 92.00,  suleymansoylu\n",
      "\tCentrality = 89.00,  yusufalabarda\n"
     ]
    }
   ],
   "source": [
    "display_max = 10  #number of nodes to display\n",
    "\n",
    "for counter in range(ncomm):\n",
    "    mask_arab = df_communities.arabic_profile==True\n",
    "    mask_comm = df_communities.Community==counter\n",
    "    community_screen_names = list(df_communities.screen_name[mask_comm & mask_arab])\n",
    "    Vsub = []\n",
    "    for v in community_screen_names:\n",
    "        if Gretweet.has_node(v):\n",
    "            nb = list(Gretweet.predecessors(v))\n",
    "            Vsub+=nb\n",
    "            Vsub.append(v)\n",
    "    print(\"Arabic profile retweet community %s with %s users\"%(counter,len(community_screen_names)))\n",
    "    G = Gretweet.subgraph(Vsub)\n",
    "    Dout = dict(G.out_degree())\n",
    "    print(\"Top out degree\")\n",
    "    Centrality = Dout\n",
    "    display_top_centrality_nodes(Centrality,display_max)\n",
    "\n",
    "for counter in range(ncomm):\n",
    "    mask_arab = df_communities.arabic_profile==False\n",
    "    mask_comm = df_communities.Community==counter\n",
    "    community_screen_names = list(df_communities.screen_name[mask_comm & mask_arab])\n",
    "    Vsub = []\n",
    "    for v in community_screen_names:\n",
    "        if Gretweet.has_node(v):\n",
    "            nb = list(Gretweet.predecessors(v))\n",
    "            Vsub+=nb\n",
    "            Vsub.append(v)\n",
    "    print(\"\\nNon-Arabic profile retweet community %s with %s users\"%(counter,len(community_screen_names)))\n",
    "    G = Gretweet.subgraph(Vsub)\n",
    "    Dout = dict(G.out_degree())\n",
    "    print(\"Top out degree\")\n",
    "    Centrality = Dout\n",
    "    display_top_centrality_nodes(Centrality,display_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet sources and their bot followers\n",
    "\n",
    "Print out the bots retweeting a retweet source in each bot community\n",
    "\n",
    "INPUT:\n",
    "1) source = screen name of retweet source\n",
    "\n",
    "OUTPUT:\n",
    "1) List of bots retweeting source in each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghadaoueiss retweeted by 191 bots in retweet graph \n",
      "\t4 bots in community 0\n",
      "\t186 bots in community 1\n",
      "\t1 bots in community 2\n"
     ]
    }
   ],
   "source": [
    "source = \"ghadaoueiss\"\n",
    "\n",
    "display_max = 0  #number of nodes to display\n",
    "\n",
    "nb = list(Gretweet.successors(source))\n",
    "print(\"%s retweeted by %s bots in retweet graph \"%(source,len(nb)))\n",
    "for counter in range(ncomm):\n",
    "    community_screen_names = list(df_communities.screen_name[df_communities.Community==counter])\n",
    "    Vsub = list(set(community_screen_names).intersection(nb))\n",
    "    print(\"\\t%s bots in community %s\"%(len(Vsub),counter))\n",
    "    \n",
    "    for cv,v in enumerate(Vsub):\n",
    "        if (cv+1)>=display_max:break\n",
    "        print(\"\\t\\tBot %s: %s\"%(cv,v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Collect Bots Created in Different Time Windows\n",
    "\n",
    "Choose a start and stop date.  This cell will find all bots in each community created between those dates and save their profiles to a csv file whose name tell us the bot community, start date, and stop date.\n",
    "\n",
    "Input:\n",
    "\n",
    "tstart = start date (string)\n",
    "\n",
    "tstop = stop date (string)\n",
    "\n",
    "df_communities = dataframe with community info\n",
    "\n",
    "ncomm = number of communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 0 with 1073 accounts\n",
      "\t57 bots in community 0 created betweet 2019-01-01 to 2019-06-01\n",
      "Community 1 with 757 accounts\n",
      "\t45 bots in community 1 created betweet 2019-01-01 to 2019-06-01\n",
      "Community 2 with 195 accounts\n",
      "\t14 bots in community 2 created betweet 2019-01-01 to 2019-06-01\n",
      "Community 3 with 0 accounts\n",
      "\t0 bots in community 3 created betweet 2019-01-01 to 2019-06-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zlisto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "tstart = '2019-01-01'\n",
    "tstop = '2019-06-01'\n",
    "\n",
    "dtstart =  datetime. strptime(tstart,\"%Y-%m-%d\")\n",
    "dtstop =  datetime. strptime(tstop,\"%Y-%m-%d\")\n",
    "\n",
    "for counter in range(ncomm+1):\n",
    "    df_comm = df_communities[df_communities.Community==counter]\n",
    "    print(\"Community %s with %s accounts\"%(counter,len(df_comm)))\n",
    "    mask0 = (df_communities.Community==counter)\n",
    "    mask1 = (pd.to_datetime(df_communities.created_at_datetime)>dtstart)\n",
    "    mask2 = (pd.to_datetime(df_communities.created_at_datetime)<=dtstop)\n",
    "    Bots_in_window = df_comm[mask0 & mask1 & mask2]\n",
    "    print(\"\\t%s bots in community %s created betweet %s to %s\"%(len(Bots_in_window),\n",
    "                                                                 counter,tstart,tstop))\n",
    "    fname = path_data + \"Bots_Community_%s_%s_to_%s.csv\"%(counter,tstart,tstop)\n",
    "    Bots_in_window.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
