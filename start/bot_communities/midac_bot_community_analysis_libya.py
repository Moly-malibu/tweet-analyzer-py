# -*- coding: utf-8 -*-
"""MIDAC Bot Community Analysis Libya.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rrTv4JkYoQx0VVVtq8leYAqh6aX1VAe8

# Bot Community Analysis
Use this notebook to analyze communities in bot retweet network

Data = Bot profiles and community membership, bot tweets

Analysis steps

1) Look at popular retweeted users, arabic profiles, and account creation dates within in bot retweet community.

3) Cluster bots by creation date.  Look at popular retweeted users and arabic profiles in each created_at community
"""

from datetime import datetime, timedelta
import numpy as np
import networkx as nx
from networkx.algorithms import community

import sqlite3,sys,os,string
import pandas as pd
import matplotlib.pyplot as plt
from os import path

from helper_retweet_network import *

#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
#import arabic_reshaper
#from bidi.algorithm import get_display

"""## Load Data

Input:

1) fname_bots_db = file of database with bot tweets

2) fname_Gretweet = file where we saved the bot retweet network

3) fname_Gsim = file where we saved retweet similarity network of bots

Output: 

1) df_profiles = dataframe with both profiles and created_at as a datetime object

2) df_communities = dataframe with bot profiles and communities

3) Gretweet = retweet network including bots and who they retweet

4) Gsim = similarity graph of bot accounts based on Jacard index of similarity network
"""

path_data = "Libya//"

fname_bots_db = path_data+"Libya_bot_forensics.db"
fname_Gretweet = path_data + "Gretweet.gpickle"
fname_Gsim = path_data + "Gsim.gpickle"
fname_bots_updated_csv = path_data+"Libya_bot_forensics_community.csv"
conn = sqlite3.connect("%s"%fname_bots_db)
df_tweets = pd.read_sql_query("SELECT * FROM tweet", conn)
df_profiles = pd.read_sql_query("SELECT * FROM user_profile", conn)
df_communities = pd.read_csv(fname_bots_updated_csv)
Gretweet = nx.read_gpickle(fname_Gretweet)
Gsim = nx.read_gpickle(fname_Gsim)
fmt = '%Y-%m-%d %H:%M:%S'

#convert created_at to a datetime object
Tdatetime = []
for s in df_profiles.created_at:
    date_time_obj = datetime.strptime(s, fmt)
    Tdatetime.append(date_time_obj)
Tdatetime = np.array(Tdatetime)
df_profiles["created_at_datetime"]  = Tdatetime
Tdatetime = []
for s in df_communities.created_at:
    date_time_obj = datetime.strptime(s, fmt)
    Tdatetime.append(date_time_obj)
Tdatetime = np.array(Tdatetime)
df_communities["created_at_datetime"]  = Tdatetime


t0 = min(Tdatetime)
ncomm  = max(df_communities.Community)+1

print("%s bots\n%s bot tweets\n%s bot communities"%(len(df_profiles),
                                                    len(df_tweets),
                                                    ncomm))

"""## Function to detect Arabic characters"""

## functions to detect if a string has arabic characters
def isarabic_char(ch):
    if ('\u0600' <= ch <= '\u06FF' or
        '\u0750' <= ch <= '\u077F' or
        '\u08A0' <= ch <= '\u08FF' or
        '\uFB50' <= ch <= '\uFDFF' or
        '\uFE70' <= ch <= '\uFEFF' or
        '\U00010E60' <= ch <= '\U00010E7F' or
        '\U0001EE00' <= ch <= '\U0001EEFF' or
                        ch == '\U0001F1E6' or #saudi flag emoji
                        ch == '\U0001F1E6'): #saudi flag emoji
        return True
    else:
        return False
    
def isarabic_str(str):
    x = False
    for ch in str:
        if isarabic_char(ch): 
            x = True
            break
    return(x)

"""## Fraction of Arabic profiles in each community"""

for counter in range(ncomm):
    mask_arab = df_communities.arabic_profile==True
    mask_comm = df_communities.Community==counter
    nc = len(list(df_communities.screen_name[mask_comm]))
    nc_arab = len(list(df_communities.screen_name[mask_comm & mask_arab]))
    frac_arab = nc_arab/nc
    print("Community %s has %.2f percent Arab profiles"%(counter,frac_arab))

"""## Top retweeted users in each community

For each community of bots, we form the subgraph containing the bots and everyone they retweet.  Then we look at the top retweeted users in this subgraph.

Input

1) display_max = number of retweet sources to display for each community
"""

display_max = 20  #number of nodes to display

for counter in range(ncomm):
    community_screen_names = list(df_communities.screen_name[df_communities.Community==counter])
    Vsub = []
    for v in community_screen_names:
        if Gretweet.has_node(v):
            nb = list(Gretweet.predecessors(v))
            Vsub+=nb
            Vsub.append(v)
    
    print("Retweet community %s with %s users"%(counter,len(community_screen_names)))
    G = Gretweet.subgraph(Vsub)
    Dout = dict(G.out_degree())
    print("Top out degree")
    Centrality = Dout
    display_top_centrality_nodes(Centrality,display_max)

"""## Top retweeted users in each (retweet,profile language) community 

For each retweet community of bots, we separate out those
with Arabic and non-Arabic profies.  
We form the subgraph containing the bots and everyone they retweet.  
Then we look at the top retweeted users in this subgraph.

Input

1) display_max = number of retweet sources to display for each community
"""

display_max = 10  #number of nodes to display

for counter in range(ncomm):
    mask_arab = df_communities.arabic_profile==True
    mask_comm = df_communities.Community==counter
    community_screen_names = list(df_communities.screen_name[mask_comm & mask_arab])
    Vsub = []
    for v in community_screen_names:
        if Gretweet.has_node(v):
            nb = list(Gretweet.predecessors(v))
            Vsub+=nb
            Vsub.append(v)
    print("Arabic profile retweet community %s with %s users"%(counter,len(community_screen_names)))
    G = Gretweet.subgraph(Vsub)
    Dout = dict(G.out_degree())
    print("Top out degree")
    Centrality = Dout
    display_top_centrality_nodes(Centrality,display_max)

for counter in range(ncomm):
    mask_arab = df_communities.arabic_profile==False
    mask_comm = df_communities.Community==counter
    community_screen_names = list(df_communities.screen_name[mask_comm & mask_arab])
    Vsub = []
    for v in community_screen_names:
        if Gretweet.has_node(v):
            nb = list(Gretweet.predecessors(v))
            Vsub+=nb
            Vsub.append(v)
    print("\nNon-Arabic profile retweet community %s with %s users"%(counter,len(community_screen_names)))
    G = Gretweet.subgraph(Vsub)
    Dout = dict(G.out_degree())
    print("Top out degree")
    Centrality = Dout
    display_top_centrality_nodes(Centrality,display_max)

"""## Retweet sources and their bot followers

Print out the bots retweeting a retweet source in each bot community

INPUT:
1) source = screen name of retweet source

OUTPUT:
1) List of bots retweeting source in each community
"""

source = "ghadaoueiss"

display_max = 0  #number of nodes to display

nb = list(Gretweet.successors(source))
print("%s retweeted by %s bots in retweet graph "%(source,len(nb)))
for counter in range(ncomm):
    community_screen_names = list(df_communities.screen_name[df_communities.Community==counter])
    Vsub = list(set(community_screen_names).intersection(nb))
    print("\t%s bots in community %s"%(len(Vsub),counter))
    
    for cv,v in enumerate(Vsub):
        if (cv+1)>=display_max:break
        print("\t\tBot %s: %s"%(cv,v))

"""## Collect Bots Created in Different Time Windows

Choose a start and stop date.  This cell will find all bots in each community created between those dates and save their profiles to a csv file whose name tell us the bot community, start date, and stop date.

Input:

tstart = start date (string)

tstop = stop date (string)

df_communities = dataframe with community info

ncomm = number of communities
"""

tstart = '2019-01-01'
tstop = '2019-06-01'

dtstart =  datetime. strptime(tstart,"%Y-%m-%d")
dtstop =  datetime. strptime(tstop,"%Y-%m-%d")

for counter in range(ncomm+1):
    df_comm = df_communities[df_communities.Community==counter]
    print("Community %s with %s accounts"%(counter,len(df_comm)))
    mask0 = (df_communities.Community==counter)
    mask1 = (pd.to_datetime(df_communities.created_at_datetime)>dtstart)
    mask2 = (pd.to_datetime(df_communities.created_at_datetime)<=dtstop)
    Bots_in_window = df_comm[mask0 & mask1 & mask2]
    print("\t%s bots in community %s created betweet %s to %s"%(len(Bots_in_window),
                                                                 counter,tstart,tstop))
    fname = path_data + "Bots_Community_%s_%s_to_%s.csv"%(counter,tstart,tstop)
    Bots_in_window.to_csv(fname)

